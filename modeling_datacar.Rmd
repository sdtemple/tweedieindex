---
title: "Modeling dataCar with tweedie Package"
author: Seth Temple
output: html_notebook
---


```{r}
library(tweedie)
library(statmod)
library(ggplot2)
library(insuranceData)
```

Import the dataset.
```{r}
data(dataCar)
summary(dataCar)
```
There do not appear to be empties. We won't do any additional wrangling.
We have continuous numerical columns and some categorical columns.
The target variable is claimcst0. We want to model loss costs with a Poisson-gamma model.

The naive approach is to set p as 1.5. Build this model with no features.
```{r}
m0 <- glm(claimcst0~1,
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.5))
summary(m0)
```

Explore the different variables. Improve the model.
```{r}
m1 <- glm(claimcst0~1+as.factor(gender),
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.5))
summary(m1)
anova(m1,m0)

print("AIC change")
print(AICtweedie(m1) - AICtweedie(m0))
```

```{r}
m2 <- glm(claimcst0~1+as.factor(gender)+as.factor(agecat),
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.5))
summary(m2)
anova(m2,m1)

print("AIC change")
print(AICtweedie(m2) - AICtweedie(m1))
```

```{r}
m3 <- glm(claimcst0~1+as.factor(gender)+as.factor(agecat)+as.factor(area),
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.5))
summary(m3)
anova(m3,m2)

print("AIC change")
print(AICtweedie(m3) - AICtweedie(m2))
```

```{r}
m4 <- glm(claimcst0~1+as.factor(gender)+as.factor(agecat)
          +as.factor(area)+veh_value,
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.5))
summary(m4)
anova(m4,m3)

print("AIC change")
print(AICtweedie(m4) - AICtweedie(m3))
```

We do not assert that this features list is the best features list to use. If we wanted to model the data for business purposes, we would spend more time modeling. This research looks into how estimating the power parameter could improve models. We only need a model that is decent and has some features. Then we see how changing p affects the model.

Use tweedie.profile to estimate p. (Explore do.smooth=TRUE vs do.smooth=FALSE)
```{r}
start <- Sys.time()

# identity link
output <- tweedie.profile(claimcst0~1, data=dataCar, link.power=1,
                          method="interpolation", verbose=2,
                          do.plot=TRUE, do.smooth=TRUE,
                          p.vec=seq(1.1,1.9,.1))

end <- Sys.time()
print(end-start)
```
```{r}
start <- Sys.time()

# identity link
output <- tweedie.profile(claimcst0~1, data=dataCar, link.power=1,
                          method="interpolation",
                          do.plot=TRUE, do.smooth=FALSE,
                          p.vec=seq(1.1,1.9,.05))

end <- Sys.time()
print(end-start)
output$p.max
output$phi.max
```

```{r}
start <- Sys.time()

# identity link
output <- tweedie.profile(claimcst0~1, data=dataCar, link.power=1,
                          method="interpolation",
                          do.plot=TRUE, do.smooth=FALSE,
                          p.vec=seq(1.1,1.9,.025))

end <- Sys.time()
print(end-start)
output$p.max
output$phi.max
```
```{r}
start <- Sys.time()

# identity link
output <- tweedie.profile(claimcst0~1, data=dataCar, link.power=1,
                          method="interpolation",
                          do.plot=TRUE, do.smooth=FALSE,
                          p.vec=seq(1.1,1.9,.01))

end <- Sys.time()
print(end-start)
output$p.max
output$phi.max
```

```{r}
start <- Sys.time()

# identity link
output <- tweedie.profile(claimcst0~1, data=dataCar, link.power=1,
                          method="interpolation",
                          do.plot=TRUE, do.smooth=FALSE,
                          p.vec=seq(1.3,1.7,.01))

end <- Sys.time()
print(end-start)
output$p.max
output$phi.max
```
MLE gives that p=1.57.

```{r}
m5 <- glm(claimcst0~1+as.factor(gender)+as.factor(agecat)
          +as.factor(area)+veh_value,
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.57))
```

Feedback functions.
```{r}
give_feedback <- function(model){
  SSR <- sum((model$residuals)**2)
  fitted_values <- model$fitted.values
  print("Squared Sum of Residuals"); print(SSR)
  print("Deviance"); print(model$deviance)
  print("AIC"); print(AICtweedie(model))
}

compare_insurance_models <- function(model1, model2){
  
  SSR1 <- sum((model1$residuals)**2)
  SSR2 <- sum((model2$residuals)**2)
  diff_SSR <- SSR1 - SSR2
  
  fitted_values1 <- model1$fitted.values
  fitted_values2 <- model2$fitted.values
  diff_fitted_values <- fitted_values1 - fitted_values2
  diff_losses <- sum(abs(diff_fitted_values))
  diff_econ = sum(model1$fitted.values - model2$fitted.values)
  
  diff_deviance <- model1$deviance - model2$deviance
  diff_AIC <- AICtweedie(model1) - AICtweedie(model2)
  
  print("Model differences are relative to the first model")
  print("Squared Sum of Residuals"); print(diff_SSR)
  print("Deviance"); print(diff_deviance)
  print("AIC"); print(diff_AIC)
  
  print("Sum of absolute differences between losses"); print(diff_losses)
  print("Total difference between losses"); print(diff_econ)
  
  print("First 10 differences in fitted losses")
  print(diff_fitted_values[1:5])
  
}
```

```{r}
give_feedback(m4)
give_feedback(m5)
```
```{r}
compare_insurance_models(m5,m4)
```

```{r}
sum(m4$fitted.values)/sum(dataCar$claimcst0)
sum(m5$fitted.values)/sum(dataCar$claimcst0)
```

Essentially, we see no difference. Sometimes actuaries use p=1.33 or p=1.66 as defaults. Let's see how things change if we use those p values.

```{r}
m6 <- glm(claimcst0~1+as.factor(gender)+as.factor(agecat)
          +as.factor(area)+veh_value,
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.33))

m7 <- glm(claimcst0~1+as.factor(gender)+as.factor(agecat)
          +as.factor(area)+veh_value,
          data=dataCar,
          family=tweedie(link.power=0, var.power=1.66))
```
```{r}
compare_insurance_models(m5,m6)
```
```{r}
compare_insurance_models(m5,m7)
```

An observation.
- We see some trends in how AIC and total difference change as p changes.
Another observation.
- I find it curious that deviance and AIC move in different directions for this data.

```{r}
sum(m5$fitted.values)/sum(dataCar$claimcst0)
sum(m6$fitted.values)/sum(dataCar$claimcst0)
sum(m7$fitted.values)/sum(dataCar$claimcst0)
```
Again, we see little change. Insurance companies want to implement new techonologies if the tech provides big advantages. Here we only see changes in the order of cents. Granted, p=1.33, p=1.5, p=1.57, and 1.66 all correspond to a Poisson-gamma model. (I guess there isn't much difference between the Poisson-gamam models for this dataset.)

We have 67856 observations. So the dataset is large. However, we have few features to differentiate between the observations. We will see if the power parameter plays a more significant role in a more complicated model.
